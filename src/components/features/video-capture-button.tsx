"use client";

import React, { useRef, useState } from "react";
import { Video, CheckCircle2, Loader2, X } from "lucide-react";
import { cn } from "@/lib/utils";
import { toast } from "sonner";

// =============================================================================
// å‹å®šç¾©
// =============================================================================

export type VideoPosition = "diagnosis" | "work" | "evidence" | string;

export interface VideoData {
  position?: VideoPosition;
  file?: File;
  previewUrl?: string;
  isProcessing?: boolean;
  error?: string;
  duration?: number; // ç§’
  transcription?: string; // éŸ³å£°èªè­˜ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå®Ÿæ³è§£èª¬ï¼‰
}

export interface VideoCaptureButtonProps {
  /** æ’®å½±ä½ç½® */
  position: VideoPosition;
  /** ãƒ©ãƒ™ãƒ«ï¼ˆè¡¨ç¤ºåï¼‰ */
  label: string;
  /** å‹•ç”»ãƒ‡ãƒ¼ã‚¿ */
  videoData?: VideoData;
  /** æ’®å½±æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ */
  onCapture: (position: VideoPosition, file: File, transcription?: string) => void | Promise<void>;
  /** ç„¡åŠ¹åŒ–ãƒ•ãƒ©ã‚° */
  disabled?: boolean;
  /** ã‚«ã‚¹ã‚¿ãƒ ã‚¯ãƒ©ã‚¹å */
  className?: string;
  /** æœ€å¤§éŒ²ç”»æ™‚é–“ï¼ˆç§’ï¼‰ */
  maxDuration?: number; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 15ç§’
  /** æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆMBï¼‰ */
  maxSizeMB?: number; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10MB
  /** ã‚«ãƒ¡ãƒ©ãƒ¢ãƒ¼ãƒ‰ï¼ˆenvironment: èƒŒé¢ã‚«ãƒ¡ãƒ©, user: å‰é¢ã‚«ãƒ¡ãƒ©ï¼‰ */
  cameraMode?: "environment" | "user";
  /** éŒ²ç”»ä¸­ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”»ç”¨ï¼‰ */
  onRecording?: (isRecording: boolean) => void;
  /** éŒ²ç”»å®Œäº†æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆBlobã‚’è¿”ã™ï¼‰ */
  onRecordComplete?: (position: VideoPosition, blob: Blob) => void | Promise<void>;
  /** ç”»è³ªãƒ¢ãƒ¼ãƒ‰ï¼ˆstandard: æ¨™æº–, high: é«˜ç”»è³ªãƒ»ãƒ–ãƒ­ã‚°ç”¨ï¼‰ */
  qualityMode?: "standard" | "high";
  /** éŸ³å£°èªè­˜ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ */
  enableTranscription?: boolean;
  /** éŸ³å£°èªè­˜å®Œäº†æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ */
  onTranscriptionComplete?: (position: VideoPosition, text: string) => void | Promise<void>;
}

// =============================================================================
// ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
// =============================================================================

/**
 * å‹•ç”»æ’®å½±ãƒœã‚¿ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
 *
 * æ©Ÿèƒ½:
 * - ã‚«ãƒ¡ãƒ©èµ·å‹•ï¼ˆãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œï¼‰
 * - æœ€å¤§éŒ²ç”»æ™‚é–“åˆ¶é™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 15ç§’ï¼‰
 * - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10MBï¼‰
 * - ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
 * - ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°çŠ¶æ…‹è¡¨ç¤º
 * - é«˜ç”»è³ªãƒ¢ãƒ¼ãƒ‰ï¼ˆVP9ã‚³ãƒ¼ãƒ‡ãƒƒã‚¯ã€ãƒ–ãƒ­ã‚°ç”¨ï¼‰
 */
export function VideoCaptureButton({
  position,
  label,
  videoData,
  onCapture,
  disabled = false,
  className,
  maxDuration = 15,
  maxSizeMB = 10,
  cameraMode = "environment",
  onRecording,
  onRecordComplete,
  qualityMode = "standard",
  enableTranscription = false,
  onTranscriptionComplete,
}: VideoCaptureButtonProps) {
  const inputRef = useRef<HTMLInputElement>(null);
  const videoRef = useRef<HTMLVideoElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);

  const handleClick = () => {
    if (disabled || isProcessing || videoData?.isProcessing) {
      return;
    }
    inputRef.current?.click();
  };

  /**
   * å¯¾å¿œã—ã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—ã‚’å–å¾—ï¼ˆå„ªå…ˆé †ä½ä»˜ãï¼‰
   */
  const getSupportedMimeType = (): string | null => {
    const mimeTypes = qualityMode === "high"
      ? [
        // é«˜ç”»è³ªãƒ¢ãƒ¼ãƒ‰: VP9ã‚’å„ªå…ˆï¼ˆVP8ã‚ˆã‚Šé«˜ç”»è³ªãƒ»é«˜åŠ¹ç‡ï¼‰
        "video/webm;codecs=vp9,opus",
        "video/webm;codecs=vp8,opus",
        "video/webm",
      ]
      : [
        // æ¨™æº–ãƒ¢ãƒ¼ãƒ‰: VP8ã‚’å„ªå…ˆï¼ˆäº’æ›æ€§é‡è¦–ï¼‰
        "video/webm;codecs=vp8,opus",
        "video/webm",
      ];

    for (const mimeType of mimeTypes) {
      if (MediaRecorder.isTypeSupported(mimeType)) {
        return mimeType;
      }
    }
    return null;
  };

  /**
   * ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”»ã‚’é–‹å§‹
   */
  const handleStartRecording = async () => {
    try {
      // é«˜ç”»è³ªãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€è§£åƒåº¦ã¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆã‚’æœ€é©åŒ–
      const videoConstraints = qualityMode === "high"
        ? {
          facingMode: cameraMode,
          width: { ideal: 1920 },
          height: { ideal: 1080 },
          frameRate: { ideal: 30 },
        }
        : { facingMode: cameraMode };

      const stream = await navigator.mediaDevices.getUserMedia({
        video: videoConstraints,
        audio: true,
      });

      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.play();
      }

      // å¯¾å¿œã—ã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—ã‚’å–å¾—
      const mimeType = getSupportedMimeType();
      if (!mimeType) {
        toast.error("ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯å‹•ç”»éŒ²ç”»ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“");
        stream.getTracks().forEach((track) => track.stop());
        return;
      }

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType,
      });

      recordedChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(recordedChunksRef.current, {
          type: "video/webm",
        });

        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        const maxSizeBytes = maxSizeMB * 1024 * 1024;
        if (blob.size > maxSizeBytes) {
          toast.error(`ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ${maxSizeMB}MBã‚’è¶…ãˆã¦ã„ã¾ã™`);
          return;
        }

        // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        stream.getTracks().forEach((track) => track.stop());

        if (videoRef.current) {
          videoRef.current.srcObject = null;
        }

        // ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        if (onRecordComplete) {
          setIsProcessing(true);
          try {
            await onRecordComplete(position, blob);
          } catch (error) {
            console.error("éŒ²ç”»å®Œäº†å‡¦ç†ã‚¨ãƒ©ãƒ¼:", error);
          } finally {
            setIsProcessing(false);
          }
        }

        // Fileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã—ã¦onCaptureã‚‚å‘¼ã³å‡ºã™
        const fileType = blob.type || "video/webm";
        const fileExtension = fileType.includes("vp9") || fileType.includes("vp8") ? "webm" : "webm";
        const fileName = `video-${position}-${Date.now()}.${fileExtension}`;
        const file = new File([blob], fileName, {
          type: fileType,
        });

        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’é€šçŸ¥
        const fileSizeMB = (file.size / (1024 * 1024)).toFixed(2);
        if (qualityMode === "high") {
          toast.success("é«˜ç”»è³ªå‹•ç”»ã‚’éŒ²ç”»ã—ã¾ã—ãŸ", {
            description: `${fileSizeMB}MB (WebM/VP9)`,
          });
        }

        // éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
        let transcription: string | undefined;
        if (enableTranscription) {
          try {
            toast.info("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­...", { duration: 2000 });
            const formData = new FormData();
            formData.append("video", file);

            const transcribeResponse = await fetch("/api/gemini/transcribe", {
              method: "POST",
              body: formData,
            });

            if (transcribeResponse.ok) {
              const transcribeData = await transcribeResponse.json();
              if (transcribeData.success && transcribeData.text) {
                transcription = transcribeData.text;
                toast.success("éŸ³å£°èªè­˜ãŒå®Œäº†ã—ã¾ã—ãŸ");
                if (onTranscriptionComplete) {
                  await onTranscriptionComplete(position, transcription!);
                }
              } else {
                console.warn("éŸ³å£°èªè­˜çµæœãŒç©ºã§ã™");
              }
            } else {
              console.error("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:", await transcribeResponse.text());
              toast.warning("éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‹•ç”»ã¯ä¿å­˜ã•ã‚Œã¾ã—ãŸ");
            }
          } catch (error) {
            console.error("éŸ³å£°èªè­˜å‡¦ç†ã‚¨ãƒ©ãƒ¼:", error);
            toast.warning("éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‹•ç”»ã¯ä¿å­˜ã•ã‚Œã¾ã—ãŸ");
          }
        }

        await onCapture(position, file, transcription);
      };

      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();
      setIsRecording(true);
      setRecordingTime(0);
      onRecording?.(true);

      // éŒ²ç”»æ™‚é–“ã®ã‚«ã‚¦ãƒ³ãƒˆ
      const timer = setInterval(() => {
        setRecordingTime((prev) => {
          const newTime = prev + 1;
          if (newTime >= maxDuration) {
            handleStopRecording();
            clearInterval(timer);
            return maxDuration;
          }
          return newTime;
        });
      }, 1000);
    } catch (error) {
      console.error("éŒ²ç”»é–‹å§‹ã‚¨ãƒ©ãƒ¼:", error);
      toast.error("ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ");
    }
  };

  /**
   * ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”»ã‚’åœæ­¢
   */
  const handleStopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      onRecording?.(false);
    }
  };

  const handleFileChange = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) {
      return;
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚»ãƒƒãƒˆ
    e.target.value = "";

    // ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒã‚§ãƒƒã‚¯
    if (!file.type.startsWith("video/")) {
      console.error("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„");
      return;
    }

    // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
    const maxSizeBytes = maxSizeMB * 1024 * 1024;
    if (file.size > maxSizeBytes) {
      console.error(`ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ${maxSizeMB}MBã‚’è¶…ãˆã¦ã„ã¾ã™`);
      return;
    }

    setIsProcessing(true);

    try {
      // éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰
      let transcription: string | undefined;
      if (enableTranscription) {
        try {
          toast.info("éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­...", { duration: 2000 });
          const formData = new FormData();
          formData.append("video", file);

          const transcribeResponse = await fetch("/api/gemini/transcribe", {
            method: "POST",
            body: formData,
          });

          if (transcribeResponse.ok) {
            const transcribeData = await transcribeResponse.json();
            if (transcribeData.success && transcribeData.text) {
              transcription = transcribeData.text;
              toast.success("éŸ³å£°èªè­˜ãŒå®Œäº†ã—ã¾ã—ãŸ");
              if (onTranscriptionComplete) {
                await onTranscriptionComplete(position, transcription!);
              }
            } else {
              console.warn("éŸ³å£°èªè­˜çµæœãŒç©ºã§ã™");
            }
          } else {
            console.error("éŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼:", await transcribeResponse.text());
            toast.warning("éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‹•ç”»ã¯ä¿å­˜ã•ã‚Œã¾ã—ãŸ");
          }
        } catch (error) {
          console.error("éŸ³å£°èªè­˜å‡¦ç†ã‚¨ãƒ©ãƒ¼:", error);
          toast.warning("éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‹•ç”»ã¯ä¿å­˜ã•ã‚Œã¾ã—ãŸ");
        }
      }

      // ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
      await onCapture(position, file, transcription);
    } catch (error) {
      console.error("å‹•ç”»å‡¦ç†ã‚¨ãƒ©ãƒ¼:", error);
    } finally {
      setIsProcessing(false);
    }
  };

  const hasVideo = !!videoData?.previewUrl;
  const isProcessingState = videoData?.isProcessing || isProcessing;

  const handleButtonClick = () => {
    if (isRecording) {
      handleStopRecording();
    } else if (onRecordComplete) {
      // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŒ²ç”»ãƒ¢ãƒ¼ãƒ‰
      handleStartRecording();
    } else {
      // ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ¢ãƒ¼ãƒ‰
      handleClick();
    }
  };

  return (
    <div className={cn("relative", className)}>
      <input
        ref={inputRef}
        type="file"
        accept="video/*"
        capture={cameraMode}
        className="hidden"
        onChange={handleFileChange}
        disabled={disabled || isProcessingState || isRecording}
      />
      <video
        ref={videoRef}
        className="hidden"
        playsInline
        muted
      />
      <button
        type="button"
        onClick={handleButtonClick}
        disabled={isProcessingState || disabled}
        className={cn(
          "w-full h-24 rounded-xl border-2 border-dashed transition-all",
          "flex flex-col items-center justify-center gap-1",
          "active:scale-95",
          hasVideo
            ? "border-blue-500 bg-blue-50 dark:bg-blue-950/20"
            : "border-slate-300 bg-slate-50 hover:border-slate-500 hover:bg-slate-100 dark:border-slate-700 dark:bg-slate-900/50 dark:hover:bg-slate-800",
          (isProcessingState || disabled) && "opacity-50 cursor-wait"
        )}
      >
        {isRecording ? (
          <div className="flex flex-col items-center gap-1">
            <div className="relative">
              <div className="w-6 h-6 rounded-full bg-red-500 animate-pulse" />
              <div className="absolute inset-0 w-6 h-6 rounded-full border-2 border-red-600 animate-ping" />
            </div>
            <span className="text-base font-medium text-red-700">éŒ²ç”»ä¸­</span>
            <span className="text-base text-red-700">
              {Math.floor(recordingTime / 60)}:{(recordingTime % 60).toString().padStart(2, "0")} / {Math.floor(maxDuration / 60)}:{(maxDuration % 60).toString().padStart(2, "0")}
            </span>
          </div>
        ) : isProcessingState ? (
          <div className="flex flex-col items-center gap-1">
            <Loader2 className="h-6 w-6 animate-spin text-slate-700" />
            <span className="text-base text-slate-700">å‡¦ç†ä¸­...</span>
          </div>
        ) : hasVideo ? (
          <div className="flex flex-col items-center gap-1">
            <CheckCircle2 className="h-6 w-6 text-blue-700 dark:text-blue-400" />
            <span className="text-base font-medium text-blue-700 dark:text-blue-300">{label}</span>
            <span className="text-base text-blue-700 dark:text-blue-500">éŒ²ç”»æ¸ˆã¿ âœ“</span>
            {videoData?.duration && (
              <span className="text-base text-blue-700 dark:text-blue-500">
                {Math.round(videoData.duration)}ç§’
              </span>
            )}
          </div>
        ) : (
          <div className="flex flex-col items-center gap-1">
            <Video className="h-6 w-6 text-slate-700 dark:text-slate-300" />
            <span className="text-base font-medium text-slate-800 dark:text-slate-300">
              ğŸ¥ {label}
            </span>
            <span className="text-base text-slate-700 dark:text-slate-300">
              æœ€å¤§{maxDuration}ç§’
            </span>
          </div>
        )}
      </button>

      {hasVideo && videoData?.previewUrl && (
        <div className="absolute -top-2 -right-2 w-12 h-12 rounded-lg overflow-hidden border-2 border-white dark:border-slate-800 shadow-md bg-slate-900 flex items-center justify-center">
          <Video className="h-6 w-6 text-white" />
        </div>
      )}
    </div>
  );
}
